# scrape_balanced_sample.py

import logging
from ntscraper import Nitter
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
from dotenv import load_dotenv
import os
from datetime import datetime

# üîå Verbindung zu MongoDB herstellen
def connect_to_mongo():
    load_dotenv()
    logging.basicConfig(level=logging.INFO)
    uri = os.getenv("MONGO_URI")
    if not uri:
        raise ValueError("‚ùå MONGO_URI fehlt in .env-Datei!")
    try:
        client = MongoClient(uri, serverSelectionTimeoutMS=3000)
        client.admin.command("ping")
        logging.info("‚úÖ Verbindung zu MongoDB erfolgreich")
        db = client["ukraineBiasDB"]
        return db["tweets_balanced"]
    except ConnectionFailure as e:
        logging.info(f"‚ùå Fehler bei Verbindung: {e}")
        return None
#Kernvariablen f√ºr die Suche
lang = "en"
since = datetime(2025, 3, 1)
until = datetime(2025, 3, 29)
# üß† Neutrale, balancierte Begriffe
terms = [
    "ukraine", "russia",
    "zelenskyy", 
    "putin",
    "kyiv", "moscow",
    "nato", "sanctions",
    "ukraine war", "ukraine conflict",
    "US peace talks", "weapons delivery",
    "russian occupation", "russian invasion",
    "#ZOV", "#SlavaUkraini"
]


# üîç Tweets sequentiell scrapen
def scrape_terms_sequential(terms, mode="term", lang="en", since=None, until=None, limit=500):
    scraper = Nitter(log_level=1)
    results = []
    for term in terms:
        try:
            logging.info(f"\nüîç Scraping: {term}")
            result = scraper.get_tweets(term, mode=mode, number=limit)
            results.append(result)
        except Exception as e:
            logging.info(f"‚ö†Ô∏è Fehler bei '{term}': {e}")
    return results

# ‚ñ∂Ô∏è Ausf√ºhrung
if __name__ == "__main__":
    collection = connect_to_mongo()
    results = scrape_terms_sequential(terms, limit=500)

    total = 0

    for i, result in enumerate(results):
        tweets = result.get("tweets", [])
        valid_tweets = []

        term = terms[i]  # Suchbegriff f√ºr Zuordnung

        for tweet in tweets:
            tweet["search_term"] = term
            tweet.pop("_id", None)  # Falls vorhanden, entfernen
            valid_tweets.append(tweet)

        if valid_tweets:
            try:
                collection.insert_many(valid_tweets, ordered=False)
                total += len(valid_tweets)
                logging.info(f"‚úÖ {len(valid_tweets)} gespeichert f√ºr '{term}'")
            except Exception as e:
                logging.info(f"‚ö†Ô∏è Fehler beim Speichern f√ºr '{term}': {e}")

    logging.info(f"\nüéâ Total gespeichert in 'tweets_balanced': {total} Tweets")